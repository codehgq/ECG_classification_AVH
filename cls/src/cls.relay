def @main(%x: Tensor[(1, 3600), float32] /* ty=Tensor[(1, 3600), float32] span=StatefulPartitionedCall/model/conv1d/conv1d/ExpandDims.x:0:0 */) -> Tensor[(1, 7), float32] {
  %0 = expand_dims(%x, axis=1) /* ty=Tensor[(1, 1, 3600), float32] span=StatefulPartitionedCall/model/conv1d/conv1d/ExpandDims:0:0 */;
  %1 = reshape(%0, newshape=[-1, 1, 1, 3600]) /* ty=Tensor[(1, 1, 1, 3600), float32] span=StatefulPartitionedCall/model/conv1d/conv1d__9:0:0 */;
  %2 = nn.conv2d(%1, meta[relay.Constant][0] /* ty=Tensor[(128, 1, 1, 50), float32] span=StatefulPartitionedCall/model/conv1d/conv1d.StatefulPartitionedCall/model/conv1d/conv1d/ExpandDims_1:0:0:0 */, strides=[1, 3], padding=[0, 23, 0, 24], channels=128, kernel_size=[1, 50]) /* ty=Tensor[(1, 128, 1, 1200), float32] span=StatefulPartitionedCall/model/conv1d/conv1d:0:0 */;
  %3 = squeeze(%2, axis=[2]) /* ty=Tensor[(1, 128, 1200), float32] span=StatefulPartitionedCall/model/conv1d/conv1d/Squeeze:0:0 */;
  %4 = add(%3, meta[relay.Constant][1] /* ty=Tensor[(1, 128, 1), float32] span=StatefulPartitionedCall/model/conv1d/BiasAdd.const_fold_opt__175:0:0 */) /* ty=Tensor[(1, 128, 1200), float32] span=StatefulPartitionedCall/model/conv1d/BiasAdd:0:0 */;
  %5 = nn.relu(%4) /* ty=Tensor[(1, 128, 1200), float32] span=StatefulPartitionedCall/model/conv1d/Relu:0:0 */;
  %6 = multiply(%5, meta[relay.Constant][2] /* ty=Tensor[(1, 128, 1), float32] span=StatefulPartitionedCall/model/batch_normalization/batchnorm/mul_1.StatefulPartitionedCall/model/batch_normalization/batchnorm/mul:0:0:0 */) /* ty=Tensor[(1, 128, 1200), float32] span=StatefulPartitionedCall/model/batch_normalization/batchnorm/mul_1:0:0 */;
  %7 = add(%6, meta[relay.Constant][3] /* ty=Tensor[(1, 128, 1), float32] span=StatefulPartitionedCall/model/batch_normalization/batchnorm/add_1.const_fold_opt__187:0:0 */) /* ty=Tensor[(1, 128, 1200), float32] span=StatefulPartitionedCall/model/batch_normalization/batchnorm/add_1:0:0 */;
  %8 = expand_dims(%7, axis=1) /* ty=Tensor[(1, 1, 128, 1200), float32] span=StatefulPartitionedCall/model/max_pooling1d/ExpandDims:0:0 */;
  %9 = reshape(%8, newshape=[-1, 128, 1200, 1]) /* ty=Tensor[(1, 128, 1200, 1), float32] span=StatefulPartitionedCall/model/max_pooling1d/MaxPool__17:0:0 */;
  %10 = nn.max_pool2d(%9, pool_size=[2, 1], strides=[3, 1], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 128, 400, 1), float32] span=StatefulPartitionedCall/model/max_pooling1d/MaxPool:0:0 */;
  %11 = squeeze(%10, axis=[3]) /* ty=Tensor[(1, 128, 400), float32] span=StatefulPartitionedCall/model/max_pooling1d/Squeeze:0:0 */;
  %12 = expand_dims(%11, axis=2) /* ty=Tensor[(1, 128, 1, 400), float32] span=StatefulPartitionedCall/model/conv1d_1/conv1d/ExpandDims:0:0 */;
  %13 = nn.conv2d(%12, meta[relay.Constant][4] /* ty=Tensor[(32, 128, 1, 7), float32] span=StatefulPartitionedCall/model/conv1d_1/conv1d.StatefulPartitionedCall/model/conv1d_1/conv1d/ExpandDims_1:0:0:0 */, padding=[0, 3, 0, 3], channels=32, kernel_size=[1, 7]) /* ty=Tensor[(1, 32, 1, 400), float32] span=StatefulPartitionedCall/model/conv1d_1/conv1d:0:0 */;
  %14 = squeeze(%13, axis=[2]) /* ty=Tensor[(1, 32, 400), float32] span=StatefulPartitionedCall/model/conv1d_1/conv1d/Squeeze:0:0 */;
  %15 = add(%14, meta[relay.Constant][5] /* ty=Tensor[(1, 32, 1), float32] span=StatefulPartitionedCall/model/conv1d_1/BiasAdd.const_fold_opt__192:0:0 */) /* ty=Tensor[(1, 32, 400), float32] span=StatefulPartitionedCall/model/conv1d_1/BiasAdd:0:0 */;
  %16 = nn.relu(%15) /* ty=Tensor[(1, 32, 400), float32] span=StatefulPartitionedCall/model/conv1d_1/Relu:0:0 */;
  %17 = multiply(%16, meta[relay.Constant][6] /* ty=Tensor[(1, 32, 1), float32] span=StatefulPartitionedCall/model/batch_normalization_1/batchnorm/mul_1.StatefulPartitionedCall/model/batch_normalization_1/batchnorm/mul:0:0:0 */) /* ty=Tensor[(1, 32, 400), float32] span=StatefulPartitionedCall/model/batch_normalization_1/batchnorm/mul_1:0:0 */;
  %18 = add(%17, meta[relay.Constant][7] /* ty=Tensor[(1, 32, 1), float32] span=StatefulPartitionedCall/model/batch_normalization_1/batchnorm/add_1.const_fold_opt__188:0:0 */) /* ty=Tensor[(1, 32, 400), float32] span=StatefulPartitionedCall/model/batch_normalization_1/batchnorm/add_1:0:0 */;
  %19 = expand_dims(%18, axis=1) /* ty=Tensor[(1, 1, 32, 400), float32] span=StatefulPartitionedCall/model/max_pooling1d_1/ExpandDims:0:0 */;
  %20 = reshape(%19, newshape=[-1, 32, 400, 1]) /* ty=Tensor[(1, 32, 400, 1), float32] span=StatefulPartitionedCall/model/max_pooling1d_1/MaxPool__33:0:0 */;
  %21 = nn.max_pool2d(%20, pool_size=[2, 1], strides=[2, 1], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 32, 200, 1), float32] span=StatefulPartitionedCall/model/max_pooling1d_1/MaxPool:0:0 */;
  %22 = squeeze(%21, axis=[3]) /* ty=Tensor[(1, 32, 200), float32] span=StatefulPartitionedCall/model/max_pooling1d_1/Squeeze:0:0 */;
  %23 = expand_dims(%22, axis=2) /* ty=Tensor[(1, 32, 1, 200), float32] span=StatefulPartitionedCall/model/conv1d_2/conv1d/ExpandDims:0:0 */;
  %24 = nn.conv2d(%23, meta[relay.Constant][8] /* ty=Tensor[(32, 32, 1, 10), float32] span=StatefulPartitionedCall/model/conv1d_2/conv1d.StatefulPartitionedCall/model/conv1d_2/conv1d/ExpandDims_1:0:0:0 */, padding=[0, 4, 0, 5], channels=32, kernel_size=[1, 10]) /* ty=Tensor[(1, 32, 1, 200), float32] span=StatefulPartitionedCall/model/conv1d_2/conv1d:0:0 */;
  %25 = squeeze(%24, axis=[2]) /* ty=Tensor[(1, 32, 200), float32] span=StatefulPartitionedCall/model/conv1d_2/conv1d/Squeeze:0:0 */;
  %26 = add(%25, meta[relay.Constant][9] /* ty=Tensor[(1, 32, 1), float32] span=StatefulPartitionedCall/model/conv1d_2/BiasAdd.const_fold_opt__174:0:0 */) /* ty=Tensor[(1, 32, 200), float32] span=StatefulPartitionedCall/model/conv1d_2/BiasAdd:0:0 */;
  %27 = nn.relu(%26) /* ty=Tensor[(1, 32, 200), float32] span=StatefulPartitionedCall/model/conv1d_2/Relu:0:0 */;
  %28 = expand_dims(%27, axis=2) /* ty=Tensor[(1, 32, 1, 200), float32] span=StatefulPartitionedCall/model/conv1d_3/conv1d/ExpandDims:0:0 */;
  %29 = nn.conv2d(%28, meta[relay.Constant][10] /* ty=Tensor[(128, 32, 1, 5), float32] span=StatefulPartitionedCall/model/conv1d_3/conv1d.StatefulPartitionedCall/model/conv1d_3/conv1d/ExpandDims_1:0:0:0 */, strides=[1, 2], padding=[0, 1, 0, 2], channels=128, kernel_size=[1, 5]) /* ty=Tensor[(1, 128, 1, 100), float32] span=StatefulPartitionedCall/model/conv1d_3/conv1d:0:0 */;
  %30 = squeeze(%29, axis=[2]) /* ty=Tensor[(1, 128, 100), float32] span=StatefulPartitionedCall/model/conv1d_3/conv1d/Squeeze:0:0 */;
  %31 = add(%30, meta[relay.Constant][11] /* ty=Tensor[(1, 128, 1), float32] span=StatefulPartitionedCall/model/conv1d_3/BiasAdd.const_fold_opt__193:0:0 */) /* ty=Tensor[(1, 128, 100), float32] span=StatefulPartitionedCall/model/conv1d_3/BiasAdd:0:0 */;
  %32 = nn.relu(%31) /* ty=Tensor[(1, 128, 100), float32] span=StatefulPartitionedCall/model/conv1d_3/Relu:0:0 */;
  %33 = expand_dims(%32, axis=1) /* ty=Tensor[(1, 1, 128, 100), float32] span=StatefulPartitionedCall/model/max_pooling1d_2/ExpandDims:0:0 */;
  %34 = reshape(%33, newshape=[-1, 128, 100, 1]) /* ty=Tensor[(1, 128, 100, 1), float32] span=StatefulPartitionedCall/model/max_pooling1d_2/MaxPool__57:0:0 */;
  %35 = nn.max_pool2d(%34, pool_size=[2, 1], strides=[2, 1], padding=[0, 0, 0, 0]) /* ty=Tensor[(1, 128, 50, 1), float32] span=StatefulPartitionedCall/model/max_pooling1d_2/MaxPool:0:0 */;
  %36 = squeeze(%35, axis=[3]) /* ty=Tensor[(1, 128, 50), float32] span=StatefulPartitionedCall/model/max_pooling1d_2/Squeeze:0:0 */;
  %37 = expand_dims(%36, axis=2) /* ty=Tensor[(1, 128, 1, 50), float32] span=StatefulPartitionedCall/model/conv1d_4/conv1d/ExpandDims:0:0 */;
  %38 = nn.conv2d(%37, meta[relay.Constant][12] /* ty=Tensor[(512, 128, 1, 5), float32] span=StatefulPartitionedCall/model/conv1d_4/conv1d.StatefulPartitionedCall/model/conv1d_4/conv1d/ExpandDims_1:0:0:0 */, padding=[0, 2, 0, 2], channels=512, kernel_size=[1, 5]) /* ty=Tensor[(1, 512, 1, 50), float32] span=StatefulPartitionedCall/model/conv1d_4/conv1d:0:0 */;
  %39 = squeeze(%38, axis=[2]) /* ty=Tensor[(1, 512, 50), float32] span=StatefulPartitionedCall/model/conv1d_4/conv1d/Squeeze:0:0 */;
  %40 = add(%39, meta[relay.Constant][13] /* ty=Tensor[(1, 512, 1), float32] span=StatefulPartitionedCall/model/conv1d_4/BiasAdd.const_fold_opt__189:0:0 */) /* ty=Tensor[(1, 512, 50), float32] span=StatefulPartitionedCall/model/conv1d_4/BiasAdd:0:0 */;
  %41 = nn.relu(%40) /* ty=Tensor[(1, 512, 50), float32] span=StatefulPartitionedCall/model/conv1d_4/Relu:0:0 */;
  %42 = expand_dims(%41, axis=2) /* ty=Tensor[(1, 512, 1, 50), float32] span=StatefulPartitionedCall/model/conv1d_5/conv1d/ExpandDims:0:0 */;
  %43 = nn.conv2d(%42, meta[relay.Constant][14] /* ty=Tensor[(128, 512, 1, 3), float32] span=StatefulPartitionedCall/model/conv1d_5/conv1d.StatefulPartitionedCall/model/conv1d_5/conv1d/ExpandDims_1:0:0:0 */, padding=[0, 1, 0, 1], channels=128, kernel_size=[1, 3]) /* ty=Tensor[(1, 128, 1, 50), float32] span=StatefulPartitionedCall/model/conv1d_5/conv1d:0:0 */;
  %44 = squeeze(%43, axis=[2]) /* ty=Tensor[(1, 128, 50), float32] span=StatefulPartitionedCall/model/conv1d_5/conv1d/Squeeze:0:0 */;
  %45 = add(%44, meta[relay.Constant][15] /* ty=Tensor[(1, 128, 1), float32] span=StatefulPartitionedCall/model/conv1d_5/BiasAdd.const_fold_opt__191:0:0 */) /* ty=Tensor[(1, 128, 50), float32] span=StatefulPartitionedCall/model/conv1d_5/BiasAdd:0:0 */;
  %46 = nn.relu(%45) /* ty=Tensor[(1, 128, 50), float32] span=StatefulPartitionedCall/model/conv1d_5/Relu:0:0 */;
  %47 = transpose(%46, axes=[0, 2, 1]) /* ty=Tensor[(1, 50, 128), float32] span=Transpose__134:0:0 */;
  %48 = reshape(%47, newshape=[-1, 6400]) /* ty=Tensor[(1, 6400), float32] span=StatefulPartitionedCall/model/flatten/Reshape:0:0 */;
  %49 = nn.dense(%48, meta[relay.Constant][16] /* ty=Tensor[(512, 6400), float32] span=StatefulPartitionedCall/model/dense/MatMul:0:0 */, units=None, out_dtype="float32") /* ty=Tensor[(1, 512), float32] span=StatefulPartitionedCall/model/dense/MatMul:0:0 */;
  %50 = add(%49, meta[relay.Constant][17] /* ty=Tensor[(512), float32] span=StatefulPartitionedCall/model/dense/BiasAdd.StatefulPartitionedCall/model/dense/BiasAdd/ReadVariableOp:0:0:0 */) /* ty=Tensor[(1, 512), float32] span=StatefulPartitionedCall/model/dense/BiasAdd:0:0 */;
  %51 = nn.relu(%50) /* ty=Tensor[(1, 512), float32] span=StatefulPartitionedCall/model/dense/Relu:0:0 */;
  %52 = nn.dense(%51, meta[relay.Constant][18] /* ty=Tensor[(7, 512), float32] span=StatefulPartitionedCall/model/dense_1/MatMul:0:0 */, units=None, out_dtype="float32") /* ty=Tensor[(1, 7), float32] span=StatefulPartitionedCall/model/dense_1/MatMul:0:0 */;
  %53 = add(%52, meta[relay.Constant][19] /* ty=Tensor[(7), float32] span=StatefulPartitionedCall/model/dense_1/BiasAdd.StatefulPartitionedCall/model/dense_1/BiasAdd/ReadVariableOp:0:0:0 */) /* ty=Tensor[(1, 7), float32] span=StatefulPartitionedCall/model/dense_1/BiasAdd:0:0 */;
  nn.softmax(%53, axis=1) /* ty=Tensor[(1, 7), float32] span=StatefulPartitionedCall/model/dense_1/Softmax:0:0 */
}

